"""
RAGç³»ç»Ÿå®‰è£…è„šæœ¬
è‡ªåŠ¨åŒ–ç¯å¢ƒé…ç½®ã€ä¾èµ–å®‰è£…å’Œåˆå§‹åŒ–è®¾ç½®

åŠŸèƒ½ï¼š
1. æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ
2. å®‰è£…Pythonä¾èµ–
3. ä¸‹è½½å’Œç¼“å­˜æ¨¡å‹
4. åˆ›å»ºå¿…è¦ç›®å½•
5. é…ç½®éªŒè¯
"""

import os
import sys
import json
import subprocess
import platform
import shutil
from pathlib import Path
import urllib.request

def print_banner():
    """æ‰“å°å®‰è£…æ¨ªå¹…"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸš€ RAGæ™ºèƒ½æ£€ç´¢ç³»ç»Ÿå®‰è£…å™¨                    â•‘
â•‘                        é«˜æ€§èƒ½ Phase 1                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    print("ğŸ” æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ...")
    
    # Pythonç‰ˆæœ¬æ£€æŸ¥
    python_version = sys.version_info
    if python_version < (3, 8):
        print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version.major}.{python_version.minor}")
        print("   è¦æ±‚: Python 3.8+")
        return False
    
    print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ“ä½œç³»ç»Ÿæ£€æŸ¥
    os_name = platform.system()
    print(f"ğŸ’» æ“ä½œç³»ç»Ÿ: {os_name} {platform.release()}")
    
    # å†…å­˜æ£€æŸ¥
    try:
        import psutil
        memory_gb = psutil.virtual_memory().total / (1024**3)
        print(f"ğŸ’¾ ç³»ç»Ÿå†…å­˜: {memory_gb:.1f}GB")
        
        if memory_gb < 4:
            print("âš ï¸ å†…å­˜è¾ƒå°‘ï¼Œå»ºè®®è‡³å°‘4GBç”¨äºæœ€ä½³æ€§èƒ½")
        
    except ImportError:
        print("âš ï¸ æ— æ³•æ£€æŸ¥å†…å­˜ä¿¡æ¯ (psutilæœªå®‰è£…)")
    
    # GPUæ£€æŸ¥
    gpu_available = False
    try:
        import torch
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name()
            print(f"ğŸ® GPUè®¾å¤‡: {gpu_name}")
            gpu_available = True
        else:
            print("ğŸ’» GPUæœªæ£€æµ‹åˆ°ï¼Œå°†ä½¿ç”¨CPU")
    except ImportError:
        print("ğŸ“¦ PyTorchæœªå®‰è£…ï¼Œç¨åå°†å®‰è£…")
    
    return True

def install_dependencies():
    """å®‰è£…Pythonä¾èµ–"""
    print("\nğŸ“¦ å®‰è£…Pythonä¾èµ–åŒ…...")
    
    # æ£€æŸ¥requirements_rag.txtæ˜¯å¦å­˜åœ¨
    req_file = Path("requirements_rag.txt")
    if not req_file.exists():
        print("âŒ requirements_rag.txt æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        # å‡çº§pip
        print("ğŸ”„ å‡çº§pip...")
        subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"], 
                      check=True, capture_output=True)
        
        # å®‰è£…åŸºç¡€ç§‘å­¦è®¡ç®—åŒ…
        print("ğŸ”¢ å®‰è£…åŸºç¡€ç§‘å­¦è®¡ç®—åŒ…...")
        basic_packages = ["numpy", "scipy", "scikit-learn"]
        subprocess.run([sys.executable, "-m", "pip", "install"] + basic_packages,
                      check=True)
        
        # å®‰è£…PyTorch (CPUç‰ˆæœ¬ï¼Œå…¼å®¹æ€§æ›´å¥½)
        print("ğŸ”¥ å®‰è£…PyTorch...")
        subprocess.run([sys.executable, "-m", "pip", "install", "torch", "torchvision", "torchaudio", "--index-url", "https://download.pytorch.org/whl/cpu"],
                      check=True)
        
        # å®‰è£…å…¶ä»–ä¾èµ–
        print("ğŸ“‹ å®‰è£…RAGç³»ç»Ÿä¾èµ–...")
        subprocess.run([sys.executable, "-m", "pip", "install", "-r", "requirements_rag.txt"],
                      check=True)
        
        print("âœ… ä¾èµ–å®‰è£…å®Œæˆ")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¾èµ–å®‰è£…å¤±è´¥: {e}")
        print("ğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. å°è¯•ä½¿ç”¨å›½å†…é•œåƒ: pip install -i https://pypi.tuna.tsinghua.edu.cn/simple")
        print("3. æ‰‹åŠ¨å®‰è£…: pip install -r requirements_rag.txt")
        return False

def create_directories():
    """åˆ›å»ºå¿…è¦ç›®å½•"""
    print("\nğŸ“ åˆ›å»ºé¡¹ç›®ç›®å½•...")
    
    directories = [
        "model_cache",
        "vector_cache", 
        "cache/embeddings",
        "cache/results",
        "logs",
        "temp"
    ]
    
    for dir_path in directories:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"  âœ… {dir_path}")
    
    return True

def download_models():
    """ä¸‹è½½å’Œç¼“å­˜æ¨¡å‹"""
    print("\nğŸ¤– ä¸‹è½½åµŒå…¥æ¨¡å‹...")
    
    try:
        # ä¸‹è½½ä¸­æ–‡åˆ†è¯æ¨¡å‹
        print("ğŸ“ åˆå§‹åŒ–ä¸­æ–‡åˆ†è¯...")
        import jieba
        # jiebaä¼šè‡ªåŠ¨ä¸‹è½½è¯å…¸ï¼Œè¿™é‡Œè§¦å‘ä¸€æ¬¡
        list(jieba.cut("æµ‹è¯•"))
        print("  âœ… jiebaä¸­æ–‡åˆ†è¯å°±ç»ª")
        
        # ä¸‹è½½sentence-transformersæ¨¡å‹
        print("ğŸ§  ä¸‹è½½åµŒå…¥æ¨¡å‹...")
        from sentence_transformers import SentenceTransformer
        
        # ä½¿ç”¨è½»é‡çº§æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model_name = "shibing624/text2vec-base-chinese"
        print(f"  ğŸ“¥ ä¸‹è½½æ¨¡å‹: {model_name}")
        
        model = SentenceTransformer(model_name, cache_folder="./model_cache")
        
        # æµ‹è¯•æ¨¡å‹
        test_embedding = model.encode(["æµ‹è¯•æ–‡æœ¬"])
        print(f"  âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œå‘é‡ç»´åº¦: {test_embedding.shape[1]}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")
        print("ğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. å°è¯•è®¾ç½®HuggingFaceé•œåƒ")
        print("3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
        return False

def setup_configuration():
    """è®¾ç½®é…ç½®æ–‡ä»¶"""
    print("\nâš™ï¸ é…ç½®RAGç³»ç»Ÿ...")
    
    config_example = Path("config.example.json")
    config_file = Path("config.json")
    
    if not config_example.exists():
        print("âŒ config.example.json ä¸å­˜åœ¨")
        return False
    
    if not config_file.exists():
        print("ğŸ“ åˆ›å»ºé…ç½®æ–‡ä»¶...")
        shutil.copy(config_example, config_file)
        print("  âœ… å·²å¤åˆ¶ config.example.json -> config.json")
        print("  âš ï¸ è¯·ç¼–è¾‘ config.json å¡«å…¥çœŸå®çš„Notioné…ç½®")
    else:
        print("  âœ… config.json å·²å­˜åœ¨")
    
    # éªŒè¯é…ç½®æ ¼å¼
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # æ£€æŸ¥RAGé…ç½®
        rag_config = config.get('knowledge_search', {}).get('rag_system', {})
        if rag_config.get('enabled', False):
            print("  âœ… RAGç³»ç»Ÿå·²å¯ç”¨")
        else:
            print("  âš ï¸ RAGç³»ç»Ÿæœªå¯ç”¨ï¼Œè¯·æ£€æŸ¥é…ç½®")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return False

def run_tests():
    """è¿è¡ŒåŸºç¡€æµ‹è¯•"""
    print("\nğŸ§ª è¿è¡ŒåŸºç¡€åŠŸèƒ½æµ‹è¯•...")
    
    try:
        # å¯¼å…¥æµ‹è¯•
        import numpy as np
        import torch
        import sentence_transformers
        import jieba
        print("  âœ… æ ¸å¿ƒä¾èµ–å¯¼å…¥æˆåŠŸ")
        
        # è¯­ä¹‰æœç´¢åŸºç¡€æµ‹è¯•
        from semantic_search import SearchConfig
        config = SearchConfig(
            embedding_model="shibing624/text2vec-base-chinese",
            device="cpu",
            enable_cache=False
        )
        print("  âœ… è¯­ä¹‰æœç´¢é…ç½®æ­£å¸¸")
        
        # æ··åˆæ£€ç´¢åŸºç¡€æµ‹è¯•
        from hybrid_retrieval import SmartQueryAnalyzer
        analyzer = SmartQueryAnalyzer()
        analysis = analyzer.analyze("æµ‹è¯•æŸ¥è¯¢")
        print(f"  âœ… æŸ¥è¯¢åˆ†ææ­£å¸¸: {analysis.query_type}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åŸºç¡€æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def print_next_steps():
    """æ‰“å°åç»­æ­¥éª¤"""
    print("\n" + "="*60)
    print("ğŸ‰ RAGç³»ç»Ÿå®‰è£…å®Œæˆï¼")
    print("\nğŸ“‹ åç»­æ­¥éª¤:")
    
    print("\n1ï¸âƒ£ é…ç½®Notion API:")
    print("   - ç¼–è¾‘ config.json")
    print("   - å¡«å…¥Notion Tokenå’Œæ•°æ®åº“ID")
    print("   - ç¡®è®¤æ•°æ®åº“å­—æ®µé…ç½®")
    
    print("\n2ï¸âƒ£ è¿è¡Œå®Œæ•´æµ‹è¯•:")
    print("   python test_rag_phase1.py")
    
    print("\n3ï¸âƒ£ å¯åŠ¨ç³»ç»Ÿ:")
    print("   python main.py")
    
    print("\n4ï¸âƒ£ ç›‘æ§æ€§èƒ½:")
    print("   - æŸ¥çœ‹logsç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶")
    print("   - ä½¿ç”¨æ€§èƒ½ç›‘æ§å·¥å…·")
    
    print("\nğŸ”§ æ•…éšœæ’é™¤:")
    print("   - æŸ¥çœ‹å®‰è£…æ—¥å¿—")
    print("   - æ£€æŸ¥ä¾èµ–ç‰ˆæœ¬å…¼å®¹æ€§")
    print("   - å‚è€ƒé¡¹ç›®READMEæ–‡æ¡£")
    
    print("\nğŸš€ äº«å—æ™ºèƒ½æ£€ç´¢ä½“éªŒï¼")

def main():
    """ä¸»å®‰è£…å‡½æ•°"""
    print_banner()
    
    install_steps = [
        ("ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥", check_system_requirements),
        ("å®‰è£…Pythonä¾èµ–", install_dependencies),
        ("åˆ›å»ºé¡¹ç›®ç›®å½•", create_directories),
        ("ä¸‹è½½AIæ¨¡å‹", download_models),
        ("é…ç½®ç³»ç»Ÿè®¾ç½®", setup_configuration),
        ("è¿è¡ŒåŸºç¡€æµ‹è¯•", run_tests)
    ]
    
    success_count = 0
    total_steps = len(install_steps)
    
    for i, (step_name, step_func) in enumerate(install_steps, 1):
        print(f"\n[{i}/{total_steps}] {step_name}")
        print("-" * 40)
        
        try:
            if step_func():
                success_count += 1
                print(f"âœ… {step_name} å®Œæˆ")
            else:
                print(f"âŒ {step_name} å¤±è´¥")
                break
        except KeyboardInterrupt:
            print(f"\nâš ï¸ ç”¨æˆ·ä¸­æ–­å®‰è£…")
            sys.exit(1)
        except Exception as e:
            print(f"âŒ {step_name} å¼‚å¸¸: {e}")
            break
    
    if success_count == total_steps:
        print_next_steps()
        return True
    else:
        print(f"\nâŒ å®‰è£…æœªå®Œæˆ ({success_count}/{total_steps} æ­¥éª¤æˆåŠŸ)")
        print("\nğŸ”§ è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ï¼Œè§£å†³é—®é¢˜åé‡æ–°è¿è¡Œå®‰è£…è„šæœ¬")
        return False

if __name__ == "__main__":
    main() 