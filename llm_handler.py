import requests
import json

class LLMHandler:
    """å¤„ç†ä¸OpenRouter APIçš„æ‰€æœ‰äº¤äº’"""
    
    def __init__(self, api_key, model="anthropic/claude-3.5-sonnet"):
        self.api_key = api_key
        self.model = model
        self.base_url = "https://openrouter.ai/api/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def send_message(self, message_content, system_prompt=None, override_model=None):
        """å‘é€æ¶ˆæ¯ç»™LLMå¹¶è·å–å›å¤"""
        try:
            # ç¡®å®šæœ¬æ¬¡è°ƒç”¨ä½¿ç”¨çš„æ¨¡å‹
            current_model = override_model or self.model

            # æ„å»ºæ¶ˆæ¯
            messages = []
            
            # å¦‚æœæœ‰ç³»ç»Ÿæç¤ºï¼Œæ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
            if system_prompt:
                messages.append({
                    "role": "system",
                    "content": system_prompt
                })
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": message_content
            })
            
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            payload = {
                "model": current_model,
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 2000
            }
            
            # å‘é€è¯·æ±‚
            response = requests.post(
                self.base_url, 
                headers=self.headers, 
                json=payload, 
                timeout=60
            )
            response.raise_for_status()
            
            # è§£æå“åº”
            data = response.json()
            
            if "choices" in data and len(data["choices"]) > 0:
                choice = data["choices"][0]
                message = choice.get("message", {})
                
                # ä¼˜å…ˆè·å–æ¨ç†å†…å®¹ï¼ˆé€‚ç”¨äºGemini 2.5 Proç­‰æ¨ç†æ¨¡å‹ï¼‰
                reasoning = message.get("reasoning", "")
                content = message.get("content", "")
                
                # å¦‚æœæœ‰æ¨ç†å†…å®¹ä¸”ä¸»è¦å†…å®¹ä¸ºç©ºæˆ–åªæ˜¯æ¢è¡Œï¼Œä½¿ç”¨æ¨ç†å†…å®¹
                if reasoning and (not content.strip() or content.strip() == ""):
                    reply = reasoning
                    print(f"ğŸ“ ä½¿ç”¨æ¨ç†æ¨¡å¼å†…å®¹ (é•¿åº¦: {len(reasoning)})")
                else:
                    reply = content
                    print(f"ğŸ“ ä½¿ç”¨æ ‡å‡†å†…å®¹ (é•¿åº¦: {len(content)})")
                
                return True, reply
            else:
                return False, "LLMå“åº”æ ¼å¼å¼‚å¸¸"
                
        except requests.exceptions.Timeout:
            return False, "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
        except requests.exceptions.RequestException as e:
            return False, f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
        except Exception as e:
            return False, f"å¤„ç†LLMå“åº”æ—¶å‡ºé”™: {e}"
    
    def generate_title(self, content, max_length=20, min_length=10):
        """ç”Ÿæˆç®€æ´æ ‡é¢˜"""
        try:
            title_prompt = f"""
ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€ä¸ªéå¸¸ç®€æ´çš„ä¸­æ–‡æ ‡é¢˜ã€‚

è¦æ±‚:
1.  **ç›´æ¥è¾“å‡º**: åªè¿”å›æ ‡é¢˜æœ¬èº«ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šã€æ€è€ƒã€å¼•å·æˆ–"æ ‡é¢˜ï¼š"è¿™æ ·çš„å‰ç¼€ã€‚
2.  **è¯­è¨€**: å¿…é¡»æ˜¯ä¸­æ–‡ã€‚
3.  **é•¿åº¦**: {min_length}åˆ°{max_length}ä¸ªæ±‰å­—ã€‚
4.  **å†…å®¹**: ç²¾å‡†æ¦‚æ‹¬æ ¸å¿ƒä¸»é¢˜ã€‚

å†…å®¹ï¼š
---
{content[:200]}
---
"""
            
            success, title = self.send_message(title_prompt)
            
            if success:
                # ç¡®ä¿æ ‡é¢˜ä¸è¶…è¿‡é™åˆ¶é•¿åº¦
                title = title.strip()
                if len(title) > max_length:
                    title = title[:max_length]
                return True, title
            else:
                return False, title
                
        except Exception as e:
            return False, f"ç”Ÿæˆæ ‡é¢˜æ—¶å‡ºé”™: {e}"
    
    def process_with_template_and_title(self, content, system_prompt, max_title_length=20, min_title_length=10, override_model=None):
        """å¤„ç†æ¶ˆæ¯å¹¶ç”Ÿæˆæ ‡é¢˜ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰"""
        try:
            # ç”Ÿæˆä¸»è¦å›å¤
            main_success, main_reply = self.send_message(content, system_prompt, override_model=override_model)
            
            if not main_success:
                return False, main_reply, None
            
            # ç”Ÿæˆæ ‡é¢˜
            title_success, title = self.generate_title(content, max_title_length, min_title_length)
            
            if not title_success:
                # å¦‚æœæ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
                title = self._generate_fallback_title(content, max_title_length)
            
            return True, main_reply, title
            
        except Exception as e:
            return False, f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}", None
    
    def _generate_fallback_title(self, content, max_length=10):
        """AIç”Ÿæˆæ ‡é¢˜å¤±è´¥æ—¶çš„å¤‡é€‰æ–¹æ¡ˆ"""
        # æ–¹æ³•1ï¼šæå–å‰Nå­—
        if len(content) <= max_length:
            return content
        
        # æ–¹æ³•2ï¼šæ™ºèƒ½æˆªå–åˆ°æ ‡ç‚¹ç¬¦å·
        for i, char in enumerate(content[:max_length+5]):
            if char in "ã€‚ï¼ï¼Ÿï¼Œï¼›":
                if i <= max_length:
                    return content[:i]
                break
        
        # æ–¹æ³•3ï¼šç®€å•æˆªå–
        return content[:max_length]
    
    def test_connection(self):
        """æµ‹è¯•OpenRouterè¿æ¥"""
        try:
            success, reply = self.send_message(
                "è¯·ç®€å•å›å¤'è¿æ¥æµ‹è¯•æˆåŠŸ'", 
                "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ï¼Œè¯·ç®€æ´å›å¤ã€‚"
            )
            
            if success:
                return True, f"OpenRouterè¿æ¥æˆåŠŸï¼LLMå›å¤: {reply[:50]}..."
            else:
                return False, f"OpenRouteræµ‹è¯•å¤±è´¥: {reply}"
                
        except Exception as e:
            return False, f"OpenRouterè¿æ¥æµ‹è¯•å‡ºé”™: {e}"
    
    def get_available_models(self):
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼ˆå¯é€‰åŠŸèƒ½ï¼‰"""
        try:
            url = "https://openrouter.ai/api/v1/models"
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            models = []
            
            for model in data.get("data", []):
                models.append({
                    "id": model.get("id", ""),
                    "name": model.get("name", ""),
                    "description": model.get("description", "")
                })
            
            return models
            
        except Exception as e:
            print(f"è·å–æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return [] 