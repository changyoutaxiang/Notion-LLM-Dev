"""
RAGç³»ç»ŸPhase 1æµ‹è¯•è„šæœ¬
æµ‹è¯•é«˜æ€§èƒ½è¯­ä¹‰æœç´¢å’Œæ··åˆæ£€ç´¢åŠŸèƒ½

æµ‹è¯•é¡¹ç›®ï¼š
1. è¯­ä¹‰æœç´¢å¼•æ“åŸºç¡€åŠŸèƒ½
2. æ··åˆæ£€ç´¢å¼•æ“é›†æˆ
3. æ€§èƒ½åŸºå‡†æµ‹è¯•
4. é”™è¯¯å¤„ç†å’Œå›é€€æœºåˆ¶
"""

import os
import json
import time
import sys
from pathlib import Path

# ç¡®ä¿å¯ä»¥å¯¼å…¥é¡¹ç›®æ¨¡å—
sys.path.append(str(Path(__file__).parent))

def load_test_config():
    """åŠ è½½æµ‹è¯•é…ç½®"""
    config_path = Path("config.example.json")
    if not config_path.exists():
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»º config.json")
        return None
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ç¡®ä¿RAGç³»ç»Ÿå¯ç”¨
        config['knowledge_search']['rag_system']['enabled'] = True
        return config
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        return None

def test_semantic_search_engine():
    """æµ‹è¯•è¯­ä¹‰æœç´¢å¼•æ“"""
    print("\nğŸ§  æµ‹è¯•è¯­ä¹‰æœç´¢å¼•æ“...")
    
    try:
        from semantic_search import create_semantic_search_engine, SearchConfig
        
        # åˆ›å»ºæµ‹è¯•é…ç½®
        config = {
            "embedding_model": "shibing624/text2vec-base-chinese",  # ä½¿ç”¨è½»é‡çº§æ¨¡å‹è¿›è¡Œæµ‹è¯•
            "device": "cpu",  # æµ‹è¯•æ—¶ä½¿ç”¨CPU
            "enable_cache": False,  # æµ‹è¯•æ—¶ç¦ç”¨ç¼“å­˜
            "batch_size": 4
        }
        
        print("ğŸ“¥ åˆå§‹åŒ–è¯­ä¹‰æœç´¢å¼•æ“...")
        engine = create_semantic_search_engine(config)
        
        # æµ‹è¯•æ•°æ®
        test_knowledge = [
            {
                "id": "test_1",
                "title": "AIæ•ˆç‡ä¸­å¿ƒä»‹ç»",
                "content": "AIæ•ˆç‡ä¸­å¿ƒæ˜¯è´Ÿè´£äººå·¥æ™ºèƒ½æŠ€æœ¯åº”ç”¨å’Œæ•ˆç‡æå‡çš„æ ¸å¿ƒéƒ¨é—¨ï¼Œä¸“æ³¨äºé€šè¿‡AIæŠ€æœ¯ä¼˜åŒ–ä¸šåŠ¡æµç¨‹ã€‚"
            },
            {
                "id": "test_2", 
                "title": "ç”¨æˆ·è½¬åŒ–ç­–ç•¥",
                "content": "ç”¨æˆ·è½¬åŒ–ç­–ç•¥åŒ…æ‹¬å¤šç§æ–¹æ³•æé«˜ç”¨æˆ·å‚ä¸åº¦å’Œè½¬åŒ–ç‡ï¼Œå¦‚ä¸ªæ€§åŒ–æ¨èã€ä¼˜åŒ–ç”¨æˆ·ä½“éªŒç­‰ã€‚"
            },
            {
                "id": "test_3",
                "title": "é¡¹ç›®ç®¡ç†æµç¨‹",
                "content": "é¡¹ç›®ç®¡ç†æµç¨‹åŒ…æ‹¬éœ€æ±‚åˆ†æã€é¡¹ç›®è§„åˆ’ã€æ‰§è¡Œç›‘æ§ã€é£é™©ç®¡ç†å’Œé¡¹ç›®äº¤ä»˜ç­‰å…³é”®ç¯èŠ‚ã€‚"
            }
        ]
        
        print("ğŸ—ï¸ æ„å»ºæµ‹è¯•ç´¢å¼•...")
        if engine.build_index(test_knowledge):
            print("âœ… ç´¢å¼•æ„å»ºæˆåŠŸ")
        else:
            print("âŒ ç´¢å¼•æ„å»ºå¤±è´¥")
            return False
        
        # æµ‹è¯•æœç´¢
        test_queries = [
            "AIæŠ€æœ¯åº”ç”¨",
            "å¦‚ä½•æé«˜è½¬åŒ–ç‡",
            "é¡¹ç›®æ‰§è¡Œè¿‡ç¨‹"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
            start_time = time.time()
            results = engine.search(query, top_k=3)
            search_time = time.time() - start_time
            
            print(f"â±ï¸ æœç´¢è€—æ—¶: {search_time:.3f}ç§’")
            print(f"ğŸ“Š æ‰¾åˆ° {len(results)} ä¸ªç»“æœ:")
            
            for i, result in enumerate(results, 1):
                print(f"  {i}. {result.title} (ç›¸ä¼¼åº¦: {result.similarity_score:.3f})")
                print(f"     ç‰‡æ®µ: {result.content_snippet[:50]}...")
        
        # æ€§èƒ½ç»Ÿè®¡
        stats = engine.get_stats()
        print(f"\nğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:")
        print(f"  - æ€»æœç´¢æ¬¡æ•°: {stats['total_searches']}")
        print(f"  - å¹³å‡æœç´¢æ—¶é—´: {stats['avg_search_time']:.3f}ç§’")
        print(f"  - å†…å­˜ä½¿ç”¨: {stats['memory_usage_mb']:.1f}MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯­ä¹‰æœç´¢å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_hybrid_retrieval():
    """æµ‹è¯•æ··åˆæ£€ç´¢å¼•æ“"""
    print("\nğŸ”€ æµ‹è¯•æ··åˆæ£€ç´¢å¼•æ“...")
    
    try:
        # è¿™é‡Œéœ€è¦æ¨¡æ‹ŸNotionKnowledgeDB
        class MockNotionKnowledgeDB:
            def search_knowledge_by_keywords(self, keywords):
                # æ¨¡æ‹Ÿå…³é”®è¯æœç´¢ç»“æœ
                return [
                    {
                        "id": "mock_1",
                        "title": "æ¨¡æ‹ŸçŸ¥è¯†æ¡ç›®1",
                        "content": "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„çŸ¥è¯†æ¡ç›®ï¼ŒåŒ…å«äº†ç›¸å…³çš„å…³é”®è¯ã€‚"
                    },
                    {
                        "id": "mock_2", 
                        "title": "æ¨¡æ‹ŸçŸ¥è¯†æ¡ç›®2",
                        "content": "è¿™æ˜¯å¦ä¸€ä¸ªæ¨¡æ‹Ÿçš„çŸ¥è¯†æ¡ç›®ï¼Œç”¨äºæµ‹è¯•å…³é”®è¯åŒ¹é…ã€‚"
                    }
                ]
        
        config = load_test_config()
        if not config:
            return False
        
        # ç®€åŒ–é…ç½®ç”¨äºæµ‹è¯•
        config['knowledge_search']['rag_system']['embedding']['model_name'] = "shibing624/text2vec-base-chinese"
        config['knowledge_search']['rag_system']['embedding']['device'] = "cpu"
        
        from hybrid_retrieval import create_hybrid_retrieval_engine
        
        mock_db = MockNotionKnowledgeDB()
        
        print("ğŸš€ åˆå§‹åŒ–æ··åˆæ£€ç´¢å¼•æ“...")
        hybrid_engine = create_hybrid_retrieval_engine(mock_db, config)
        
        # æµ‹è¯•æŸ¥è¯¢åˆ†æ
        from hybrid_retrieval import SmartQueryAnalyzer
        analyzer = SmartQueryAnalyzer()
        
        test_queries = [
            "ä»€ä¹ˆæ˜¯AIæ•ˆç‡ä¸­å¿ƒ",
            "å¦‚ä½•æé«˜ç”¨æˆ·è½¬åŒ–ç‡",
            "é¡¹ç›®ç®¡ç†"
        ]
        
        for query in test_queries:
            print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: '{query}'")
            
            # æŸ¥è¯¢åˆ†æ
            analysis = analyzer.analyze(query)
            print(f"  ğŸ“‹ æŸ¥è¯¢ç±»å‹: {analysis.query_type}")
            print(f"  ğŸ”‘ å…³é”®è¯: {analysis.processed_keywords}")
            print(f"  ğŸ“Š å¤æ‚åº¦: {analysis.complexity}")
            
            # ç”±äºè¯­ä¹‰æœç´¢å¼•æ“å¯èƒ½æœªå®Œå…¨åˆå§‹åŒ–ï¼Œè¿™é‡Œä¸»è¦æµ‹è¯•æ¶æ„
            print("  âœ… æŸ¥è¯¢åˆ†æå®Œæˆ")
        
        # æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        stats = hybrid_engine.get_search_stats()
        print(f"\nğŸ“ˆ æ··åˆæ£€ç´¢ç»Ÿè®¡:")
        for key, value in stats.items():
            print(f"  - {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ··åˆæ£€ç´¢å¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_notion_integration():
    """æµ‹è¯•Notioné›†æˆ"""
    print("\nğŸ”— æµ‹è¯•Notioné›†æˆ...")
    
    try:
        config = load_test_config()
        if not config:
            return False
        
        # æ£€æŸ¥Notioné…ç½®
        notion_config = config.get('notion', {})
        required_fields = ['token', 'knowledge_database_id']
        
        for field in required_fields:
            if not notion_config.get(field):
                print(f"âš ï¸ Notioné…ç½®ç¼ºå°‘ {field}ï¼Œè·³è¿‡å®é™…APIæµ‹è¯•")
                return True
        
        from notion_knowledge_db import NotionKnowledgeDB
        
        print("ğŸ”— åˆå§‹åŒ–NotionçŸ¥è¯†åº“...")
        knowledge_db = NotionKnowledgeDB(config)
        
        # æµ‹è¯•æ™ºèƒ½æœç´¢æ¥å£
        test_query = "æµ‹è¯•æŸ¥è¯¢"
        print(f"ğŸ” æµ‹è¯•æ™ºèƒ½æœç´¢: '{test_query}'")
        
        results = knowledge_db.smart_search_knowledge(test_query, max_results=3)
        print(f"ğŸ“Š æœç´¢ç»“æœ: {len(results)} ä¸ª")
        
        for i, result in enumerate(results, 1):
            print(f"  {i}. {result.get('title', 'N/A')}")
            if 'similarity_score' in result:
                print(f"     ç›¸ä¼¼åº¦: {result['similarity_score']:.3f}")
            if 'source_type' in result:
                print(f"     æ¥æº: {result['source_type']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Notioné›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance_benchmark():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    print("\nâš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•...")
    
    try:
        # ç®€å•çš„æ€§èƒ½æµ‹è¯•
        import psutil
        import platform
        
        print(f"ğŸ’» ç³»ç»Ÿä¿¡æ¯:")
        print(f"  - æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
        print(f"  - CPUæ ¸å¿ƒæ•°: {psutil.cpu_count()}")
        print(f"  - å†…å­˜æ€»é‡: {psutil.virtual_memory().total / (1024**3):.1f}GB")
        print(f"  - å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / (1024**3):.1f}GB")
        
        # æµ‹è¯•ä¾èµ–åŒ…å¯¼å…¥é€Ÿåº¦
        import_tests = [
            "numpy",
            "torch", 
            "sentence_transformers",
            "faiss",
            "jieba"
        ]
        
        print(f"\nğŸ“¦ ä¾èµ–åŒ…å¯¼å…¥æµ‹è¯•:")
        for package in import_tests:
            try:
                start_time = time.time()
                __import__(package)
                import_time = time.time() - start_time
                print(f"  âœ… {package}: {import_time:.3f}ç§’")
            except ImportError:
                print(f"  âŒ {package}: æœªå®‰è£…")
            except Exception as e:
                print(f"  âš ï¸ {package}: å¯¼å…¥å¤±è´¥ ({e})")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½åŸºå‡†æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª RAGç³»ç»ŸPhase 1æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    test_results = []
    
    # 1. æ€§èƒ½åŸºå‡†æµ‹è¯•
    test_results.append(("æ€§èƒ½åŸºå‡†", test_performance_benchmark()))
    
    # 2. è¯­ä¹‰æœç´¢å¼•æ“æµ‹è¯•
    test_results.append(("è¯­ä¹‰æœç´¢å¼•æ“", test_semantic_search_engine()))
    
    # 3. æ··åˆæ£€ç´¢å¼•æ“æµ‹è¯•
    test_results.append(("æ··åˆæ£€ç´¢å¼•æ“", test_hybrid_retrieval()))
    
    # 4. Notioné›†æˆæµ‹è¯•
    test_results.append(("Notioné›†æˆ", test_notion_integration()))
    
    # ç»“æœæ±‡æ€»
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RAGç³»ç»ŸPhase 1åŸºç¡€åŠŸèƒ½æ­£å¸¸")
        print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. å®‰è£…å®Œæ•´ä¾èµ–: pip install -r requirements_rag.txt")
        print("2. é…ç½®Notion API: å¤åˆ¶ config.example.json ä¸º config.json å¹¶å¡«å…¥çœŸå®é…ç½®")
        print("3. è¿è¡Œå®é™…æµ‹è¯•: python test_rag_phase1.py")
        print("4. ç›‘æ§æ€§èƒ½è¡¨ç°å¹¶è¿›è¡Œä¼˜åŒ–")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥Pythonç¯å¢ƒå’Œä¾èµ–å®‰è£…")
        print("2. éªŒè¯é…ç½®æ–‡ä»¶æ ¼å¼")
        print("3. ç¡®è®¤ç½‘ç»œè¿æ¥æ­£å¸¸")
        print("4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 