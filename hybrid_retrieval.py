"""
æ··åˆæ£€ç´¢å¼•æ“
æ•´åˆå…³é”®è¯ç²¾ç¡®åŒ¹é…å’Œè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ï¼Œæä¾›æœ€ä½³æ£€ç´¢ä½“éªŒ

ç‰¹æ€§ï¼š
- å¤šç­–ç•¥èåˆï¼ˆå…³é”®è¯ + è¯­ä¹‰ + æƒé‡æ’åºï¼‰
- æ™ºèƒ½ç»“æœæ’åºå’Œå»é‡
- è‡ªé€‚åº”æœç´¢ç­–ç•¥
- ç»“æœè´¨é‡è¯„ä¼°
"""

import time
import hashlib
from typing import List, Dict, Tuple, Optional, Union
from dataclasses import dataclass, asdict
from collections import defaultdict

import numpy as np
from loguru import logger

from semantic_search import HighPerformanceSemanticSearch, SearchResult, SearchConfig
from notion_knowledge_db import NotionKnowledgeDB

@dataclass
class HybridSearchConfig:
    """æ··åˆæœç´¢é…ç½®"""
    # ç­–ç•¥æƒé‡
    keyword_weight: float = 0.3
    semantic_weight: float = 0.5
    
    # èåˆå‚æ•°
    fusion_method: str = "weighted_sum"  # weighted_sum, rrf, cascade
    max_results_per_strategy: int = 10
    final_top_k: int = 5
    
    # æ’åºæƒé‡
    similarity_weight: float = 0.4
    priority_weight: float = 0.2
    frequency_weight: float = 0.2
    recency_weight: float = 0.1
    authority_weight: float = 0.1
    
    # è´¨é‡æ§åˆ¶
    min_similarity_threshold: float = 0.2
    enable_deduplication: bool = True
    enable_reranking: bool = True

@dataclass
class QueryAnalysis:
    """æŸ¥è¯¢åˆ†æç»“æœ"""
    original_query: str
    processed_keywords: List[str]
    query_type: str  # informational, navigational, transactional
    complexity: str  # simple, medium, complex
    requires_semantic: bool = True
    requires_keyword: bool = True

class SmartQueryAnalyzer:
    """æ™ºèƒ½æŸ¥è¯¢åˆ†æå™¨"""
    
    def __init__(self):
        # æŸ¥è¯¢æ¨¡å¼
        self.patterns = {
            'question_words': ['ä»€ä¹ˆ', 'æ€ä¹ˆ', 'å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'å“ªé‡Œ', 'å“ªä¸ª', 'è°', 'ä½•æ—¶'],
            'navigation_words': ['æ‰“å¼€', 'æ‰¾åˆ°', 'æŸ¥çœ‹', 'è¿›å…¥', 'è®¿é—®'],
            'action_words': ['åˆ›å»º', 'åˆ é™¤', 'ä¿®æ”¹', 'æ›´æ–°', 'é…ç½®', 'è®¾ç½®']
        }
    
    def analyze(self, query: str) -> QueryAnalysis:
        """åˆ†ææŸ¥è¯¢æ„å›¾å’Œç‰¹å¾"""
        query = query.strip()
        
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(query)
        
        # åˆ†ææŸ¥è¯¢ç±»å‹
        query_type = self._classify_query_type(query)
        
        # åˆ†æå¤æ‚åº¦
        complexity = self._analyze_complexity(query)
        
        # å†³å®šæœç´¢ç­–ç•¥
        requires_semantic = len(query) > 5 or any(word in query for word in self.patterns['question_words'])
        requires_keyword = len(keywords) > 0
        
        return QueryAnalysis(
            original_query=query,
            processed_keywords=keywords,
            query_type=query_type,
            complexity=complexity,
            requires_semantic=requires_semantic,
            requires_keyword=requires_keyword
        )
    
    def _extract_keywords(self, query: str) -> List[str]:
        """æå–å…³é”®è¯"""
        import jieba
        
        # ä½¿ç”¨jiebaåˆ†è¯
        words = list(jieba.cut(query))
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'åŠ', 'æˆ–', 'ä¹Ÿ', 'äº†', 'å°±', 'éƒ½', 'è¦', 'èƒ½', 'ä¼š'}
        keywords = [word.strip() for word in words 
                   if len(word.strip()) > 1 and word.strip() not in stop_words]
        
        return keywords
    
    def _classify_query_type(self, query: str) -> str:
        """åˆ†ç±»æŸ¥è¯¢ç±»å‹"""
        if any(word in query for word in self.patterns['question_words']):
            return "informational"
        elif any(word in query for word in self.patterns['navigation_words']):
            return "navigational"  
        elif any(word in query for word in self.patterns['action_words']):
            return "transactional"
        else:
            return "informational"
    
    def _analyze_complexity(self, query: str) -> str:
        """åˆ†ææŸ¥è¯¢å¤æ‚åº¦"""
        if len(query) < 10:
            return "simple"
        elif len(query) < 30:
            return "medium"
        else:
            return "complex"

class ResultFusion:
    """ç»“æœèåˆå™¨"""
    
    def __init__(self, config: HybridSearchConfig):
        self.config = config
    
    def fuse_results(self, 
                    keyword_results: List[SearchResult],
                    semantic_results: List[SearchResult]) -> List[SearchResult]:
        """èåˆå¤šç­–ç•¥æœç´¢ç»“æœ"""
        
        if self.config.fusion_method == "weighted_sum":
            return self._weighted_sum_fusion(keyword_results, semantic_results)
        elif self.config.fusion_method == "rrf":
            return self._reciprocal_rank_fusion(keyword_results, semantic_results)
        elif self.config.fusion_method == "cascade":
            return self._cascade_fusion(keyword_results, semantic_results)
        else:
            # é»˜è®¤ï¼šç®€å•åˆå¹¶
            return self._simple_merge(keyword_results, semantic_results)
    
    def _weighted_sum_fusion(self, 
                           keyword_results: List[SearchResult],
                           semantic_results: List[SearchResult]) -> List[SearchResult]:
        """åŠ æƒæ±‚å’Œèåˆ"""
        
        # åˆ›å»ºç»“æœå­—å…¸
        result_dict = {}
        
        # å¤„ç†å…³é”®è¯ç»“æœ
        for i, result in enumerate(keyword_results):
            key = result.knowledge_id
            score = (1.0 - i / len(keyword_results)) * self.config.keyword_weight
            
            if key not in result_dict:
                result_dict[key] = result
                result_dict[key].similarity_score = score
                result_dict[key].source_type = "keyword"
            else:
                result_dict[key].similarity_score += score
                result_dict[key].source_type = "hybrid"
        
        # å¤„ç†è¯­ä¹‰ç»“æœ
        for i, result in enumerate(semantic_results):
            key = result.knowledge_id
            score = result.similarity_score * self.config.semantic_weight
            
            if key not in result_dict:
                result_dict[key] = result
                result_dict[key].similarity_score = score
                result_dict[key].source_type = "semantic"
            else:
                result_dict[key].similarity_score += score
                result_dict[key].source_type = "hybrid"
        
        # æ’åºå¹¶è¿”å›
        fused_results = list(result_dict.values())
        fused_results.sort(key=lambda x: x.similarity_score, reverse=True)
        
        return fused_results[:self.config.final_top_k]
    
    def _reciprocal_rank_fusion(self,
                              keyword_results: List[SearchResult],
                              semantic_results: List[SearchResult]) -> List[SearchResult]:
        """å€’æ•°æ’åèåˆï¼ˆRRFï¼‰"""
        
        result_scores = defaultdict(float)
        result_items = {}
        k = 60  # RRFå‚æ•°
        
        # å…³é”®è¯ç»“æœRRF
        for rank, result in enumerate(keyword_results, 1):
            key = result.knowledge_id
            result_scores[key] += self.config.keyword_weight / (k + rank)
            if key not in result_items:
                result_items[key] = result
                result_items[key].source_type = "keyword"
            else:
                result_items[key].source_type = "hybrid"
        
        # è¯­ä¹‰ç»“æœRRF
        for rank, result in enumerate(semantic_results, 1):
            key = result.knowledge_id
            result_scores[key] += self.config.semantic_weight / (k + rank)
            if key not in result_items:
                result_items[key] = result
                result_items[key].source_type = "semantic"
            else:
                result_items[key].source_type = "hybrid"
        
        # æ›´æ–°åˆ†æ•°å¹¶æ’åº
        for key, score in result_scores.items():
            result_items[key].similarity_score = score
        
        fused_results = list(result_items.values())
        fused_results.sort(key=lambda x: x.similarity_score, reverse=True)
        
        return fused_results[:self.config.final_top_k]
    
    def _cascade_fusion(self,
                       keyword_results: List[SearchResult],
                       semantic_results: List[SearchResult]) -> List[SearchResult]:
        """çº§è”èåˆï¼šä¼˜å…ˆå…³é”®è¯ï¼Œä¸è¶³æ—¶è¡¥å……è¯­ä¹‰"""
        
        result_dict = {}
        
        # ä¼˜å…ˆæ·»åŠ å…³é”®è¯ç»“æœ
        for result in keyword_results:
            key = result.knowledge_id
            result_dict[key] = result
            result_dict[key].source_type = "keyword"
        
        # è¡¥å……è¯­ä¹‰ç»“æœ
        for result in semantic_results:
            key = result.knowledge_id
            if key not in result_dict:
                result_dict[key] = result
                result_dict[key].source_type = "semantic"
        
        # æŒ‰åŸå§‹åˆ†æ•°æ’åº
        fused_results = list(result_dict.values())
        fused_results.sort(key=lambda x: x.similarity_score, reverse=True)
        
        return fused_results[:self.config.final_top_k]
    
    def _simple_merge(self,
                     keyword_results: List[SearchResult],
                     semantic_results: List[SearchResult]) -> List[SearchResult]:
        """ç®€å•åˆå¹¶å»é‡"""
        
        seen_ids = set()
        merged_results = []
        
        # å…ˆæ·»åŠ å…³é”®è¯ç»“æœ
        for result in keyword_results:
            if result.knowledge_id not in seen_ids:
                seen_ids.add(result.knowledge_id)
                merged_results.append(result)
        
        # å†æ·»åŠ è¯­ä¹‰ç»“æœ
        for result in semantic_results:
            if result.knowledge_id not in seen_ids:
                seen_ids.add(result.knowledge_id)
                merged_results.append(result)
        
        return merged_results[:self.config.final_top_k]

class AdvancedRanking:
    """é«˜çº§æ’åºç®—æ³•"""
    
    def __init__(self, config: HybridSearchConfig):
        self.config = config
    
    def rerank_results(self, results: List[SearchResult], 
                      knowledge_db: NotionKnowledgeDB) -> List[SearchResult]:
        """é‡æ–°æ’åºç»“æœ"""
        
        if not self.config.enable_reranking or not results:
            return results
        
        try:
            # è·å–é¢å¤–çš„æ’åºç‰¹å¾
            enhanced_results = []
            
            for result in results:
                enhanced_result = self._enhance_result_features(result, knowledge_db)
                enhanced_results.append(enhanced_result)
            
            # è®¡ç®—ç»¼åˆåˆ†æ•°
            for result in enhanced_results:
                composite_score = self._calculate_composite_score(result)
                result.similarity_score = composite_score
            
            # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
            enhanced_results.sort(key=lambda x: x.similarity_score, reverse=True)
            
            logger.info(f"ğŸ”„ é‡æ–°æ’åºå®Œæˆï¼Œè°ƒæ•´äº† {len(enhanced_results)} ä¸ªç»“æœ")
            
            return enhanced_results
            
        except Exception as e:
            logger.warning(f"âš ï¸ é‡æ–°æ’åºå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ’åº: {e}")
            return results
    
    def _enhance_result_features(self, result: SearchResult, 
                               knowledge_db: NotionKnowledgeDB) -> SearchResult:
        """å¢å¼ºç»“æœç‰¹å¾"""
        
        # è¿™é‡Œå¯ä»¥ä»Notionè·å–é¢å¤–ä¿¡æ¯
        # æ¯”å¦‚ä¼˜å…ˆçº§ã€ä½¿ç”¨é¢‘ç‡ã€æœ€åæ›´æ–°æ—¶é—´ç­‰
        
        # ä¸ºç®€åŒ–å®ç°ï¼Œä½¿ç”¨é»˜è®¤å€¼
        result.metadata.update({
            'priority_score': 0.5,  # å¯ä»¥ä»Notionä¼˜å…ˆçº§å­—æ®µè·å–
            'frequency_score': 0.5,  # å¯ä»¥ä»ä½¿ç”¨é¢‘ç‡å­—æ®µè·å–
            'recency_score': 0.5,   # å¯ä»¥ä»æ›´æ–°æ—¶é—´è®¡ç®—
            'authority_score': 0.5   # å¯ä»¥ä»çŸ¥è¯†æƒå¨æ€§è¯„ä¼°
        })
        
        return result
    
    def _calculate_composite_score(self, result: SearchResult) -> float:
        """è®¡ç®—ç»¼åˆåˆ†æ•°"""
        
        similarity_score = result.similarity_score
        priority_score = result.metadata.get('priority_score', 0.5)
        frequency_score = result.metadata.get('frequency_score', 0.5)
        recency_score = result.metadata.get('recency_score', 0.5)
        authority_score = result.metadata.get('authority_score', 0.5)
        
        composite_score = (
            similarity_score * self.config.similarity_weight +
            priority_score * self.config.priority_weight +
            frequency_score * self.config.frequency_weight +
            recency_score * self.config.recency_weight +
            authority_score * self.config.authority_weight
        )
        
        return composite_score

class HybridRetrievalEngine:
    """æ··åˆæ£€ç´¢å¼•æ“ä¸»ç±»"""
    
    def __init__(self, knowledge_db: NotionKnowledgeDB, config: Dict):
        self.knowledge_db = knowledge_db
        self.hybrid_config = HybridSearchConfig(**config.get('hybrid_search', {}))
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.query_analyzer = SmartQueryAnalyzer()
        self.result_fusion = ResultFusion(self.hybrid_config)
        self.advanced_ranking = AdvancedRanking(self.hybrid_config)
        
        # è¯­ä¹‰æœç´¢å¼•æ“
        self.semantic_engine = None
        self._initialize_semantic_engine(config)
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_searches": 0,
            "keyword_only": 0,
            "semantic_only": 0,
            "hybrid_searches": 0,
            "avg_response_time": 0.0
        }
        
        logger.info("ğŸš€ æ··åˆæ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_semantic_engine(self, config: Dict):
        """åˆå§‹åŒ–è¯­ä¹‰æœç´¢å¼•æ“"""
        try:
            if config.get('knowledge_search', {}).get('rag_system', {}).get('enabled', False):
                embedding_config = config['knowledge_search']['rag_system']['embedding']
                
                # æ˜ å°„é…ç½®å‚æ•°ï¼ˆå¤„ç†å‚æ•°åä¸åŒ¹é…ï¼‰
                search_config_params = {
                    'embedding_model': embedding_config.get('model_name', 'BAAI/bge-large-zh-v1.5'),
                    'device': embedding_config.get('device', 'auto'),
                    'max_seq_length': embedding_config.get('max_seq_length', 512),
                    'batch_size': embedding_config.get('batch_size', 32),
                    'enable_gpu': embedding_config.get('enable_gpu', True),
                    'similarity_threshold': config['knowledge_search']['rag_system']['search'].get('similarity_threshold', 0.3),
                    'max_results': config['knowledge_search']['rag_system']['search'].get('max_results', 10),
                    'chunk_size': config['knowledge_search']['rag_system']['search'].get('chunk_size', 300),
                    'chunk_overlap': config['knowledge_search']['rag_system']['search'].get('chunk_overlap', 50),
                    'enable_cache': config['knowledge_search']['rag_system']['search'].get('enable_caching', True),
                    'cache_ttl_hours': config['knowledge_search']['rag_system']['search'].get('cache_ttl_hours', 24),
                    'enable_batch_processing': config['knowledge_search']['rag_system']['search'].get('enable_batch_processing', True)
                }
                
                search_config = SearchConfig(**search_config_params)
                self.semantic_engine = HighPerformanceSemanticSearch(search_config)
                
                if not self.semantic_engine.initialize_model():
                    logger.error("âŒ è¯­ä¹‰æœç´¢å¼•æ“åˆå§‹åŒ–å¤±è´¥")
                    self.semantic_engine = None
                else:
                    logger.success("âœ… è¯­ä¹‰æœç´¢å¼•æ“å°±ç»ª")
        except Exception as e:
            logger.error(f"âŒ è¯­ä¹‰æœç´¢å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
            self.semantic_engine = None
    
    def build_semantic_index(self, force_rebuild: bool = False) -> bool:
        """æ„å»ºè¯­ä¹‰ç´¢å¼•"""
        if not self.semantic_engine:
            logger.warning("âš ï¸ è¯­ä¹‰æœç´¢å¼•æ“æœªå¯ç”¨")
            return False
        
        try:
            # ä»Notionè·å–æ‰€æœ‰çŸ¥è¯†æ¡ç›®
            logger.info("ğŸ“¥ ä»Notionè·å–çŸ¥è¯†åº“æ•°æ®...")
            
            # è¿™é‡Œéœ€è¦å®ç°ä»NotionKnowledgeDBè·å–æ‰€æœ‰æ¡ç›®çš„æ–¹æ³•
            # æš‚æ—¶ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            knowledge_items = self._get_all_knowledge_items()
            
            if not knowledge_items:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°çŸ¥è¯†æ¡ç›®")
                return False
            
            # æ„å»ºè¯­ä¹‰ç´¢å¼•
            return self.semantic_engine.build_index(knowledge_items, force_rebuild)
            
        except Exception as e:
            logger.error(f"âŒ æ„å»ºè¯­ä¹‰ç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def _get_all_knowledge_items(self) -> List[Dict]:
        """è·å–æ‰€æœ‰çŸ¥è¯†æ¡ç›®"""
        try:
            if self.knowledge_db:
                return self.knowledge_db.get_all_knowledge_items()
            else:
                logger.warning("âš ï¸  NotionKnowledgeDBæœªåˆå§‹åŒ–")
                return []
        except Exception as e:
            logger.error(f"âŒ è·å–çŸ¥è¯†æ¡ç›®å¤±è´¥: {e}")
            return []
    
    def intelligent_search(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """æ™ºèƒ½æœç´¢ä¸»å…¥å£"""
        start_time = time.time()
        
        try:
            # åˆ†ææŸ¥è¯¢
            query_analysis = self.query_analyzer.analyze(query)
            logger.info(f"ğŸ” æŸ¥è¯¢åˆ†æ: {query_analysis.query_type}, å¤æ‚åº¦: {query_analysis.complexity}")
            
            # å†³å®šæœç´¢ç­–ç•¥
            keyword_results = []
            semantic_results = []
            
            # å…³é”®è¯æœç´¢
            if query_analysis.requires_keyword and query_analysis.processed_keywords:
                keyword_results = self._keyword_search(query_analysis.processed_keywords)
                logger.info(f"ğŸ“ å…³é”®è¯æœç´¢: {len(keyword_results)} ä¸ªç»“æœ")
            
            # è¯­ä¹‰æœç´¢
            if query_analysis.requires_semantic and self.semantic_engine:
                semantic_results = self._semantic_search(query, max_results)
                logger.info(f"ğŸ§  è¯­ä¹‰æœç´¢: {len(semantic_results)} ä¸ªç»“æœ")
            
            # èåˆç»“æœ
            if keyword_results and semantic_results:
                fused_results = self.result_fusion.fuse_results(keyword_results, semantic_results)
                self.stats["hybrid_searches"] += 1
                logger.info("ğŸ”€ æ··åˆæœç´¢å®Œæˆ")
            elif keyword_results:
                fused_results = keyword_results[:max_results]
                self.stats["keyword_only"] += 1
                logger.info("ğŸ“ ä»…å…³é”®è¯æœç´¢")
            elif semantic_results:
                fused_results = semantic_results[:max_results]
                self.stats["semantic_only"] += 1
                logger.info("ğŸ§  ä»…è¯­ä¹‰æœç´¢")
            else:
                fused_results = []
                logger.warning("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            
            # é«˜çº§æ’åº
            if fused_results:
                fused_results = self.advanced_ranking.rerank_results(fused_results, self.knowledge_db)
            
            # å»é‡å¤„ç†
            if self.hybrid_config.enable_deduplication:
                fused_results = self._deduplicate_results(fused_results)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["total_searches"] += 1
            search_time = time.time() - start_time
            self.stats["avg_response_time"] = (
                (self.stats["avg_response_time"] * (self.stats["total_searches"] - 1) + search_time) /
                self.stats["total_searches"]
            )
            
            logger.success(f"âœ… æ™ºèƒ½æœç´¢å®Œæˆ: '{query}' â†’ {len(fused_results)} ä¸ªç»“æœï¼Œè€—æ—¶: {search_time:.3f}ç§’")
            
            return fused_results
            
        except Exception as e:
            logger.error(f"âŒ æ™ºèƒ½æœç´¢å¤±è´¥: {e}")
            return []
    
    def _keyword_search(self, keywords: List[str]) -> List[SearchResult]:
        """å…³é”®è¯æœç´¢"""
        try:
            # ä½¿ç”¨ç°æœ‰çš„NotionKnowledgeDBæœç´¢
            notion_results = self.knowledge_db.search_knowledge_by_keywords(keywords)
            
            # è½¬æ¢ä¸ºSearchResultæ ¼å¼
            search_results = []
            for i, item in enumerate(notion_results):
                result = SearchResult(
                    knowledge_id=item.get('id', str(i)),
                    title=item.get('title', ''),
                    content_snippet=item.get('content', '')[:300],
                    similarity_score=1.0 - (i * 0.1),  # ç®€å•é€’å‡åˆ†æ•°
                    source_type='keyword',
                    metadata={'rank': i + 1},
                    full_content=item.get('content', '')
                )
                search_results.append(result)
            
            return search_results[:self.hybrid_config.max_results_per_strategy]
            
        except Exception as e:
            logger.error(f"âŒ å…³é”®è¯æœç´¢å¤±è´¥: {e}")
            return []
    
    def _semantic_search(self, query: str, max_results: int) -> List[SearchResult]:
        """è¯­ä¹‰æœç´¢"""
        if not self.semantic_engine:
            return []
        
        try:
            return self.semantic_engine.search(
                query,
                top_k=min(max_results, self.hybrid_config.max_results_per_strategy)
            )
        except Exception as e:
            logger.error(f"âŒ è¯­ä¹‰æœç´¢å¤±è´¥: {e}")
            return []
    
    def _deduplicate_results(self, results: List[SearchResult]) -> List[SearchResult]:
        """å»é‡å¤„ç†"""
        seen_ids = set()
        unique_results = []
        
        for result in results:
            if result.knowledge_id not in seen_ids:
                seen_ids.add(result.knowledge_id)
                unique_results.append(result)
        
        if len(unique_results) < len(results):
            logger.info(f"ğŸ§¹ å»é‡å¤„ç†: {len(results)} â†’ {len(unique_results)} ä¸ªç»“æœ")
        
        return unique_results
    
    def get_search_stats(self) -> Dict:
        """è·å–æœç´¢ç»Ÿè®¡ä¿¡æ¯"""
        total = self.stats["total_searches"]
        if total == 0:
            return self.stats
        
        return {
            **self.stats,
            "keyword_ratio": self.stats["keyword_only"] / total,
            "semantic_ratio": self.stats["semantic_only"] / total,
            "hybrid_ratio": self.stats["hybrid_searches"] / total
        }

# åˆ›å»ºæ··åˆæ£€ç´¢å¼•æ“çš„å·¥å‚å‡½æ•°
def create_hybrid_retrieval_engine(knowledge_db: NotionKnowledgeDB, config: Dict) -> HybridRetrievalEngine:
    """åˆ›å»ºæ··åˆæ£€ç´¢å¼•æ“å®ä¾‹"""
    return HybridRetrievalEngine(knowledge_db, config) 